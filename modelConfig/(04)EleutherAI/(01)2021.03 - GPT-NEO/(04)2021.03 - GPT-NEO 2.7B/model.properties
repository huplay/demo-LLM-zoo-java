# GPT-NEO/ADA
name = EleutherAI GPT-NEO ADA (2.7B)
transformer.type = ELEUTHERAI_NEO

# Main dimensions
hidden.size = 2560
feedforward.size = 10240
decoder.count = 32
attention.head.count = 20
epsilon = 1e-5f
attention.local.size = 256

# Tokenizer config
tokenizer = GPT-2
tokenizer.config = GPT-2
token.count = 50257
end.of.text.token = 50256
max.length = 2048

# Parameter config
parameter.repo = https://huggingface.co/EleutherAI/gpt-neo-2.7B
parameter.files = model.safetensors
transformer.parameter.format = transformer.{name}
decoder.parameter.format = transformer.h.{decoderId}.{name}
