# BLOOM/176B !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
name = BLOOM 176B
transformer.type = HUGGING_FACE_BLOOM

# Main dimensions
hidden.size = 14336
feedforward.size = 57344
decoder.count = 70
attention.head.count = 112
epsilon = 1e-5f

# Tokenizer config
tokenizer = GPT-2
tokenizer.config = BLOOM
token.count = 250880
end.of.text.token = 2
max.length = 2048

# Parameter config
#parameter.repo = https://huggingface.co/bigscience/bloom
#parameter.files = model_00001-of-00072.safetensors ... model_00072-of-00072.safetensors
transformer.parameter.format = {name}
decoder.parameter.format = h.{decoderId}.{name}
