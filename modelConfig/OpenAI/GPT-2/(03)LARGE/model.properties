# GPT2/LARGE
name = OpenAI GPT-2 LARGE (774M)
transformer.type = OPENAI_GPT_2

# Main dimensions
hidden.size = 1280
feedforward.size = 5120
decoder.count = 36
attention.head.count = 20
epsilon = 1e-5f

# Tokenizer config
tokenizer = GPT-2
tokenizer.config = GPT-2
token.count = 50257
end.of.text.token = 50256
max.length = 1024

# Parameter config
parameter.files = model.safetensors
transformer.parameter.format = {name}
decoder.parameter.format = h.{decoderId}.{name}