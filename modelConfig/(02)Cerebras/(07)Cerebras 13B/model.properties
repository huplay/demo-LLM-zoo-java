# Cerebras/13B
name = Cerebras 13B
transformer.type = OPENAI_GPT_2

# Main dimensions
hidden.size = 5120
feedforward.size = 20480
decoder.count = 40
attention.head.count = 40
epsilon = 1e-5f

# Tokenizer config
tokenizer = GPT-2
tokenizer.config = GPT-2
token.count = 50257
end.of.text.token = 50256
max.length = 2048

# Parameter config
parameter.repo = https://huggingface.co/cerebras/Cerebras-GPT-13B
parameter.repo.branch = refs%2Fpr%2F10
parameter.files = model-00001-of-00002.safetensors, model-00002-of-00002.safetensors
transformer.parameter.format = transformer.{name}
decoder.parameter.format = transformer.h.{decoderId}.{name}
